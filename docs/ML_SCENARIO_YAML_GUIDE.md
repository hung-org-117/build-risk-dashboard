# ML Scenario YAML Configuration Guide

H∆∞·ªõng d·∫´n vi·∫øt file YAML ƒë·ªÉ c·∫•u h√¨nh ML Dataset Scenario.

## üìã C·∫•u Tr√∫c C∆° B·∫£n

```yaml
scenario:         # Required - Th√¥ng tin scenario
  name: "..."
  description: "..."

data_source:      # Optional - L·ªçc d·ªØ li·ªáu
  repositories: ...
  builds: ...

features:         # Optional - Ch·ªçn features
  dag_features: [...]

splitting:        # Required - Chi·∫øn l∆∞·ª£c chia t√°ch
  strategy: "..."
  group_by: "..."
  config: ...

preprocessing:    # Optional - Ti·ªÅn x·ª≠ l√Ω
  missing_values_strategy: "..."

output:           # Optional - ƒê·ªãnh d·∫°ng output
  format: "parquet"
```

---

## üìå Section: `scenario` (Required)

| Field | Type | Required | Default | M√¥ t·∫£ |
|-------|------|----------|---------|-------|
| `name` | string | ‚úÖ | - | T√™n duy nh·∫•t c·ªßa scenario |
| `description` | string | ‚ùå | null | M√¥ t·∫£ chi ti·∫øt |
| `version` | string | ‚ùå | "1.0" | Phi√™n b·∫£n |

```yaml
scenario:
  name: "my_experiment_v1"
  description: "Testing language generalization"
  version: "1.0"
```

---

## üìå Section: `data_source`

C·∫•u h√¨nh l·ªçc repositories v√† builds t·ª´ database.

### Repositories Filter

| Field | Type | Values | M√¥ t·∫£ |
|-------|------|--------|-------|
| `filter_by` | enum | `all`, `by_language`, `by_name`, `by_owner` | C√°ch l·ªçc |
| `languages` | list | - | Ng√¥n ng·ªØ (n·∫øu `filter_by: by_language`) |
| `repo_names` | list | - | T√™n repo (n·∫øu `filter_by: by_name`) |
| `owners` | list | - | Owners (n·∫øu `filter_by: by_owner`) |

### Builds Filter

| Field | Type | M√¥ t·∫£ |
|-------|------|-------|
| `date_range.start` | date | Ng√†y b·∫Øt ƒë·∫ßu (YYYY-MM-DD) |
| `date_range.end` | date | Ng√†y k·∫øt th√∫c |
| `conclusions` | list | `["success", "failure"]` |
| `exclude_bots` | bool | Lo·∫°i b·ªè bot commits (default: true) |

```yaml
data_source:
  repositories:
    filter_by: "by_language"
    languages: ["python", "javascript", "java"]
  builds:
    date_range:
      start: "2024-01-01"
      end: "2024-12-31"
    conclusions: ["success", "failure"]
    exclude_bots: true
  ci_provider: "github_actions"  # or "all", "circleci"
```

---

## üìå Section: `features`

| Field | Type | M√¥ t·∫£ |
|-------|------|-------|
| `dag_features` | list | Patterns h·ªó tr·ª£ wildcard |
| `scan_metrics` | object | `{sonarqube: [...], trivy: [...]}` |
| `exclude` | list | Features c·∫ßn lo·∫°i b·ªè |

### Feature Patterns (Wildcards)

| Pattern | M√¥ t·∫£ |
|---------|-------|
| `build_*` | Build metadata (ID, status, duration, timing) |
| `git_*` | Git operations (commits, branches, diffs) |
| `log_*` | Build logs (tests, frameworks) |
| `repo_*` | Repository stats (age, SLOC) |
| `pr_*` | Pull request info |
| `team_*` | Team metrics |
| `history_*` | Temporal features (prev builds, fail rates) |
| `author_*` | Author experience |
| `devops_*` | DevOps/CI config changes |

### Scan Metrics

Thu th·∫≠p metrics t·ª´ c√¥ng c·ª• qu√©t b·∫£o m·∫≠t.

#### SonarQube Metrics (Available)

| Metric | Type | M√¥ t·∫£ |
|--------|------|-------|
| `bugs` | int | S·ªë bugs ph√°t hi·ªán |
| `vulnerabilities` | int | L·ªó h·ªïng b·∫£o m·∫≠t |
| `code_smells` | int | Code smells |
| `coverage` | float | % Test coverage |
| `duplicated_lines_density` | float | % Duplicate code |
| `reliability_rating` | str | A-E rating |
| `security_rating` | str | A-E rating |

#### Trivy Metrics (Available)

| Metric | Type | M√¥ t·∫£ |
|--------|------|-------|
| `critical` | int | Critical vulnerabilities |
| `high` | int | High severity |
| `medium` | int | Medium severity |
| `low` | int | Low severity |
| `total` | int | Total vulnerabilities |
| `has_critical` | bool | Has critical issues |

```yaml
features:
  dag_features:
    - "build_*"
    - "git_*"
    - "history_*"
  scan_metrics:
    sonarqube: 
      - "bugs"
      - "vulnerabilities"
      - "code_smells"
      - "coverage"
    trivy: 
      - "critical"
      - "high"
      - "medium"
  exclude:
    - "git_raw_*"
```

> [!NOTE]
> Scan metrics ƒë∆∞·ª£c merge t·ª´ `FeatureVector.scan_metrics`. Ch√∫ng ƒë∆∞·ª£c thu th·∫≠p t·ª± ƒë·ªông khi builds ƒë√£ c√≥ k·∫øt qu·∫£ scan t·ª´ Trivy ho·∫∑c SonarQube.

---

## üìå Section: `splitting` (Required)

### Strategies

| Strategy | M√¥ t·∫£ | Required Config |
|----------|-------|-----------------|
| `stratified_within_group` | Chia ƒë·ªÅu trong m·ªói group | `ratios`, `stratify_by` |
| `leave_one_out` | M·ªôt group l√†m test | `test_groups` |
| `leave_two_out` | Hai groups l√†m val/test | `test_groups`, `val_groups` |
| `imbalanced_train` | Gi·∫£m samples c·ªßa 1 label | `reduce_label`, `reduce_ratio` |
| `extreme_novelty` | Group+label ‚Üí test only | `novelty_group`, `novelty_label` |

### Group By Dimensions

| Value | M√¥ t·∫£ |
|-------|-------|
| `language_group` | Groups: backend, fullstack, scripting, other |
| `time_of_day` | Theo gi·ªù trong ng√†y |
| `percentage_of_builds_before` | Theo % builds tr∆∞·ªõc ƒë√≥ |
| `number_of_builds_before` | Theo s·ªë builds tr∆∞·ªõc ƒë√≥ |

### Examples

#### Stratified Within Group (Baseline)
```yaml
splitting:
  strategy: "stratified_within_group"
  group_by: "language_group"
  config:
    ratios:
      train: 0.70
      val: 0.15
      test: 0.15
    stratify_by: "outcome"
```

#### Leave One Out
```yaml
splitting:
  strategy: "leave_one_out"
  group_by: "language_group"
  config:
    test_groups: ["backend"]       # Python, Java, Go, Rust
    val_groups: ["fullstack"]      # JavaScript
    # Remaining groups ‚Üí train
```

#### Imbalanced Train
```yaml
splitting:
  strategy: "imbalanced_train"
  group_by: "language_group"
  config:
    ratios:
      train: 0.70
      val: 0.15
      test: 0.15
    reduce_label: 1      # 0=success, 1=failure
    reduce_ratio: 0.5    # Gi·∫£m 50%
```

#### Extreme Novelty
```yaml
splitting:
  strategy: "extreme_novelty"
  group_by: "language_group"
  config:
    novelty_group: "backend"   # Group
    novelty_label: 1           # Label (failure)
    ratios:
      train: 0.85
      val: 0.15
    # (group=backend AND label=1) ‚Üí Test only
```

---

## üìå Section: `preprocessing`

| Field | Type | Values | Default |
|-------|------|--------|---------|
| `missing_values_strategy` | enum | `drop_row`, `fill`, `mean`, `skip_feature` | `drop_row` |
| `fill_value` | any | - | 0 |
| `normalization_method` | enum | `z_score`, `min_max`, `robust`, `none` | `z_score` |
| `strict_mode` | bool | - | false |

```yaml
preprocessing:
  missing_values_strategy: "fill"
  fill_value: 0
  normalization_method: "z_score"
  strict_mode: false
```

---

## üìå Section: `output`

| Field | Type | Values | Default |
|-------|------|--------|---------|
| `format` | enum | `parquet`, `csv`, `pickle` | `parquet` |
| `include_metadata` | bool | - | true |

```yaml
output:
  format: "parquet"
  include_metadata: true
```

---

## ‚ö†Ô∏è Validation Rules

1. **Required sections**: `scenario`, `splitting`
2. **Ratios must sum to 1.0**: `train + val + test = 1.0`
3. **Strategy-specific requirements**:
   - `leave_one_out`: ph·∫£i c√≥ `test_groups`
   - `leave_two_out`: ph·∫£i c√≥ `test_groups` v√† `val_groups`
   - `imbalanced_train`: ph·∫£i c√≥ `reduce_label`
   - `extreme_novelty`: ph·∫£i c√≥ `novelty_group` v√† `novelty_label`
4. **Filter dependencies**:
   - `filter_by: by_language` ‚Üí ph·∫£i c√≥ `languages`
   - `filter_by: by_name` ‚Üí ph·∫£i c√≥ `repo_names`

---

## üìù Complete Example

```yaml
# =============================================================================
# Scenario: Stratified Within Language Group (Baseline 70-15-15)
# =============================================================================

scenario:
  name: "baseline_language_stratified"
  description: "Baseline split 70-15-15 stratified by language group"
  version: "1.0"

data_source:
  repositories:
    filter_by: "all"
  builds:
    date_range:
      start: "2024-01-01"
      end: "2024-12-31"
    conclusions: ["success", "failure"]
    exclude_bots: true
  ci_provider: "github_actions"

features:
  dag_features:
    - "build_*"
    - "git_*"
    - "log_*"
    - "repo_*"
    - "history_*"

splitting:
  strategy: "stratified_within_group"
  group_by: "language_group"
  config:
    ratios:
      train: 0.70
      val: 0.15
      test: 0.15
    stratify_by: "outcome"

preprocessing:
  missing_values_strategy: "fill"
  fill_value: 0
  normalization_method: "z_score"

output:
  format: "parquet"
  include_metadata: true
```
